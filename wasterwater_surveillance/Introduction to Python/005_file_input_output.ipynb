{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Input and Output in Python\n",
    "\n",
    "In bioinformatics and computational biology, handling large datasets is a crucial task. Many types of biological data, such as AMR gene profiles, whole-genome sequencing results, variant annotations, and expression datasets, are stored in files. These files can be CSV (Comma-Separated Values), FASTA (for sequences), TSV (Tab-Separated Values), or plain text files.\n",
    "\n",
    "Python provides built-in tools and external libraries that allow us to efficiently read, process, and write these files. Instead of manually handling large datasets, Python automates these operations, making it easier to analyze thousands of genes, filter resistance markers, extract sequence motifs, or generate reports.\n",
    "\n",
    "---\n",
    "\n",
    "## ** Why Work with Files?**\n",
    "- Data in **CSV (Comma-Separated Values)** format is commonly used for **storing structured data** (e.g., AMR gene profiles, sequencing results).\n",
    "- Instead of manually entering data, we can **read from a file** and process thousands of records automatically.\n",
    "- File handling allows **storing results** in a structured way after analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## ** Key Operations in File Handling**\n",
    "Python provides built-in functions to **read, process, and write files** efficiently:\n",
    "- **Reading a file (`open()`, `read()`, `readline()`, `readlines()`)**\n",
    "- **Processing data line by line**\n",
    "- **Using `csv` and `pandas` for structured file handling**\n",
    "- **Writing processed data back into a file (`write()`, `csv.writer()`, `pandas.to_csv()`)**\n",
    "\n",
    "---\n",
    "\n",
    "## ** File Types Commonly Used in Bioinformatics**\n",
    "| File Type | Description | Example Usage |\n",
    "|-----------|------------|--------------|\n",
    "| `.csv` | Comma-Separated Values | AMR gene datasets, metadata tables |\n",
    "| `.txt` | Plain text files | FASTA headers, gene lists |\n",
    "| `.fasta` | Sequence data format | DNA/protein sequences |\n",
    "| `.tsv` | Tab-Separated Values | Expression data, genome annotations |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Reading an AMR Dataset (Example)**\n",
    "```python\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# The one way to open and read a CSV file\n",
    "with open(\"/home/analysis/Desktop/PHA4GE_Training_Materials/data/Synthetic_AMR_Dataset.csv\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        print(row)  # Prints each row as a list\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample_ID      Gene Resistance_Class  Detected  MIC_µg/mL\n",
      "0   Sample_1  blaCTX-M      Beta-lactam      True        4.0\n",
      "1   Sample_2      mecA      Methicillin      True       16.0\n",
      "2   Sample_3      tetM     Tetracycline     False        NaN\n",
      "3   Sample_4     aadA1   Aminoglycoside      True        8.0\n",
      "4   Sample_5      ermB        Macrolide     False        NaN\n",
      "5   Sample_6    blaTEM      Beta-lactam      True        2.0\n",
      "6   Sample_7      vanA       Vancomycin      True       32.0\n",
      "7   Sample_8    blaOXA      Beta-lactam     False        NaN\n",
      "8   Sample_9      mphA        Macrolide      True        1.0\n",
      "9  Sample_10      sul1      Sulfonamide      True        2.0\n"
     ]
    }
   ],
   "source": [
    "# The following part is new\n",
    "# In here we are importing other modules into our cell. So that we can use it in the following code as abbreviations\n",
    "\n",
    "# There is an easy way to do it as always!\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "amr_df = pd.read_csv(\"/home/analysis/Desktop/PHA4GE_Training_Materials/data/Synthetic_AMR_Dataset.csv\")\n",
    "\n",
    "print(amr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample_ID      Gene Resistance_Class  Detected  MIC_µg/mL\n",
      "0   Sample_1  blaCTX-M      Beta-lactam      True        4.0\n",
      "1   Sample_2      mecA      Methicillin      True       16.0\n",
      "2   Sample_3      tetM     Tetracycline     False        NaN\n",
      "3   Sample_4     aadA1   Aminoglycoside      True        8.0\n",
      "4   Sample_5      ermB        Macrolide     False        NaN\n",
      "5   Sample_6    blaTEM      Beta-lactam      True        2.0\n",
      "6   Sample_7      vanA       Vancomycin      True       32.0\n",
      "7   Sample_8    blaOXA      Beta-lactam     False        NaN\n",
      "8   Sample_9      mphA        Macrolide      True        1.0\n",
      "9  Sample_10      sul1      Sulfonamide      True        2.0\n"
     ]
    }
   ],
   "source": [
    "# can I recall the csv file again?\n",
    "\n",
    "# Let's try.\n",
    "\n",
    "print(amr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Sample_ID      Gene Resistance_Class  Detected  MIC_µg/mL\n",
      "0  Sample_1  blaCTX-M      Beta-lactam      True        4.0\n",
      "1  Sample_2      mecA      Methicillin      True       16.0\n",
      "2  Sample_3      tetM     Tetracycline     False        NaN\n",
      "3  Sample_4     aadA1   Aminoglycoside      True        8.0\n",
      "4  Sample_5      ermB        Macrolide     False        NaN\n"
     ]
    }
   ],
   "source": [
    "# We've done it! So let's go deeper now.\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(amr_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Rows: 10\n",
      "Total Columns: 5\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows and columns\n",
    "num_rows, num_cols = amr_df.shape\n",
    "print(f\"\\nTotal Rows: {num_rows}\")\n",
    "print(f\"Total Columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "['Sample_ID', 'Gene', 'Resistance_Class', 'Detected', 'MIC_µg/mL']\n"
     ]
    }
   ],
   "source": [
    "# Display column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(amr_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types:\n",
      "Sample_ID            object\n",
      "Gene                 object\n",
      "Resistance_Class     object\n",
      "Detected               bool\n",
      "MIC_µg/mL           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types of each column\n",
    "print(\"\\nData Types:\")\n",
    "print(amr_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Per Column:\n",
      "Sample_ID           0\n",
      "Gene                0\n",
      "Resistance_Class    0\n",
      "Detected            0\n",
      "MIC_µg/mL           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"\\nMissing Values Per Column:\")\n",
    "print(amr_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Sample_ID         10 non-null     object \n",
      " 1   Gene              10 non-null     object \n",
      " 2   Resistance_Class  10 non-null     object \n",
      " 3   Detected          10 non-null     bool   \n",
      " 4   MIC_µg/mL         7 non-null      float64\n",
      "dtypes: bool(1), float64(1), object(3)\n",
      "memory usage: 458.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display dataset summary\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(amr_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Gene  Detected\n",
      "0  blaCTX-M      True\n",
      "1      mecA      True\n",
      "2      tetM     False\n",
      "3     aadA1      True\n",
      "4      ermB     False\n",
      "5    blaTEM      True\n",
      "6      vanA      True\n",
      "7    blaOXA     False\n",
      "8      mphA      True\n",
      "9      sul1      True\n"
     ]
    }
   ],
   "source": [
    "filtered_amr_df = amr_df[[\"Gene\", \"Detected\"]]\n",
    "print(filtered_amr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save this file we can use the following code.\n",
    "# But be careful about the file path.\n",
    "\n",
    "filtered_amr_df.to_csv(\"/mnt/data/filtered_amr_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.0\n",
      "##fileDate=20220125\n",
      "##source=lofreq call -f freyja/data/NC_045512_Hu-1.fasta -o test.vcf freyja/data/test.bam\n",
      "##reference=freyja/data/NC_045512_Hu-1.fasta\n",
      "##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Raw Depth\">\n",
      "##INFO=<ID=AF,Number=1,Type=Float,Description=\"Allele Frequency\">\n",
      "##INFO=<ID=SB,Number=1,Type=Integer,Description=\"Phred-scaled strand bias at this position\">\n",
      "##INFO=<ID=DP4,Number=4,Type=Integer,Description=\"Counts for ref-forward bases, ref-reverse, alt-forward and alt-reverse bases\">\n",
      "##INFO=<ID=INDEL,Number=0,Type=Flag,Description=\"Indicates that the variant is an INDEL.\">\n",
      "##INFO=<ID=CONSVAR,Number=0,Type=Flag,Description=\"Indicates that the variant is a consensus variant (as opposed to a low frequency variant).\">\n"
     ]
    }
   ],
   "source": [
    "# Now we can use another file type which is VCF \n",
    "\n",
    "# Let's designate our target file_path\n",
    "file_path = \"data/test.vcf\"\n",
    "\n",
    "# Let's open it.\n",
    "with open(file_path, \"r\") as file:\n",
    "    for _ in range(10):  # and print first 10 lines\n",
    "        print(file.readline().strip())\n",
    "        \n",
    "# What else we can do with thi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCF File Inspection\n",
    "\n",
    "The first 10 lines of the VCF file contain metadata and headers, confirming it follows the VCF format (v4.0).\n",
    "These metadata lines (##) describe:\n",
    "\n",
    "The file format and source (VCFv4.0, lofreq call).\n",
    "\n",
    "The reference genome used (NC_045512_Hu-1.fasta).\n",
    "\n",
    "Various INFO fields, such as:\n",
    "\n",
    "DP → Raw sequencing depth.\n",
    "\n",
    "AF → Allele frequency.\n",
    "\n",
    "SB → Phred-scaled strand bias.\n",
    "\n",
    "DP4 → Counts for ref-forward, ref-reverse, alt-forward, alt-reverse bases.\n",
    "\n",
    "INDEL → Flag for insertion/deletion variants.\n",
    "\n",
    "CONSVAR → Flag for consensus variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "vcf_file_path = \"data/test.vcf\"  # Update this to match your file path\n",
    "\n",
    "# Extract relevant variant data from the VCF file\n",
    "vcf_data = []\n",
    "\n",
    "# Open and read the VCF file line by line\n",
    "with open(vcf_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\"#\"):  # Skip metadata/header lines\n",
    "            columns = line.strip().split(\"\\t\")\n",
    "            chrom = columns[0]  # Chromosome\n",
    "            pos = columns[1]  # Position\n",
    "            ref = columns[3]  # Reference allele\n",
    "            alt = columns[4]  # Alternate allele\n",
    "            qual = columns[5]  # Quality score\n",
    "\n",
    "            # Store extracted data\n",
    "            vcf_data.append([chrom, pos, ref, alt, qual])\n",
    "\n",
    "# Convert extracted data into a DataFrame\n",
    "vcf_df = pd.DataFrame(vcf_data, columns=[\"Chromosome\", \"Position\", \"Reference\", \"Alternate\", \"Quality\"])\n",
    "\n",
    "# Save the extracted data as a CSV file\n",
    "# vcf_df.to_csv(\"extracted_variants.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "# print(\"Extracted VCF data saved to 'extracted_variants.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_045512.2', '441', 'G', 'A', '105'],\n",
       " ['NC_045512.2', '1055', 'G', 'A', '1592'],\n",
       " ['NC_045512.2', '1191', 'C', 'T', '11391'],\n",
       " ['NC_045512.2', '1267', 'C', 'T', '9741'],\n",
       " ['NC_045512.2', '2184', 'A', 'C', '154']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_045512.2', '441', 'G', 'A', '105'],\n",
       " ['NC_045512.2', '1055', 'G', 'A', '1592'],\n",
       " ['NC_045512.2', '1191', 'C', 'T', '11391'],\n",
       " ['NC_045512.2', '1267', 'C', 'T', '9741'],\n",
       " ['NC_045512.2', '2184', 'A', 'C', '154']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[3:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_045512.2', '2973', 'C', 'T', '1395'],\n",
       " ['NC_045512.2', '3037', 'C', 'T', '13537'],\n",
       " ['NC_045512.2', '4897', 'C', 'T', '159'],\n",
       " ['NC_045512.2', '5184', 'C', 'T', '3943'],\n",
       " ['NC_045512.2', '5457', 'C', 'T', '949'],\n",
       " ['NC_045512.2', '6996', 'T', 'C', '80'],\n",
       " ['NC_045512.2', '8782', 'C', 'T', '32957'],\n",
       " ['NC_045512.2', '8883', 'T', 'C', '72'],\n",
       " ['NC_045512.2', '9203', 'G', 'A', '10829'],\n",
       " ['NC_045512.2', '9678', 'T', 'C', '1593'],\n",
       " ['NC_045512.2', '11005', 'C', 'A', '4808'],\n",
       " ['NC_045512.2', '11414', 'C', 'T', '246'],\n",
       " ['NC_045512.2', '12235', 'A', 'C', '117'],\n",
       " ['NC_045512.2', '12583', 'T', 'A', '67'],\n",
       " ['NC_045512.2', '14256', 'A', 'C', '75'],\n",
       " ['NC_045512.2', '14408', 'C', 'T', '1357'],\n",
       " ['NC_045512.2', '16247', 'C', 'T', '99'],\n",
       " ['NC_045512.2', '16255', 'C', 'T', '77'],\n",
       " ['NC_045512.2', '17000', 'C', 'T', '115'],\n",
       " ['NC_045512.2', '17474', 'C', 'A', '106'],\n",
       " ['NC_045512.2', '17496', 'A', 'G', '6152'],\n",
       " ['NC_045512.2', '18060', 'C', 'T', '14317'],\n",
       " ['NC_045512.2', '18096', 'T', 'C', '125'],\n",
       " ['NC_045512.2', '18311', 'T', 'C', '121'],\n",
       " ['NC_045512.2', '18395', 'C', 'T', '82'],\n",
       " ['NC_045512.2', '19547', 'C', 'T', '851'],\n",
       " ['NC_045512.2', '20396', 'A', 'G', '489'],\n",
       " ['NC_045512.2', '21618', 'C', 'G', '375'],\n",
       " ['NC_045512.2', '21792', 'A', 'C', '4658'],\n",
       " ['NC_045512.2', '21849', 'A', 'C', '75'],\n",
       " ['NC_045512.2', '21974', 'G', 'T', '82'],\n",
       " ['NC_045512.2', '21987', 'G', 'A', '4045'],\n",
       " ['NC_045512.2', '22009', 'C', 'A', '330'],\n",
       " ['NC_045512.2', '22206', 'A', 'G', '1045'],\n",
       " ['NC_045512.2', '22296', 'A', 'G', '103'],\n",
       " ['NC_045512.2', '22482', 'C', 'T', '79'],\n",
       " ['NC_045512.2', '22995', 'C', 'A', '3384'],\n",
       " ['NC_045512.2', '23403', 'A', 'G', '6370'],\n",
       " ['NC_045512.2', '23525', 'C', 'T', '125'],\n",
       " ['NC_045512.2', '23601', 'C', 'T', '66'],\n",
       " ['NC_045512.2', '23604', 'C', 'G', '13373'],\n",
       " ['NC_045512.2', '23607', 'G', 'T', '532'],\n",
       " ['NC_045512.2', '23618', 'A', 'G', '83'],\n",
       " ['NC_045512.2', '24410', 'G', 'A', '267'],\n",
       " ['NC_045512.2', '24780', 'A', 'G', '84'],\n",
       " ['NC_045512.2', '25469', 'C', 'T', '10803'],\n",
       " ['NC_045512.2', '25606', 'G', 'A', '64'],\n",
       " ['NC_045512.2', '26542', 'C', 'T', '362'],\n",
       " ['NC_045512.2', '26767', 'T', 'C', '5916'],\n",
       " ['NC_045512.2', '27752', 'C', 'T', '2820'],\n",
       " ['NC_045512.2', '27920', 'C', 'T', '167'],\n",
       " ['NC_045512.2', '27924', 'A', 'C', '1081'],\n",
       " ['NC_045512.2', '28144', 'T', 'C', '17994'],\n",
       " ['NC_045512.2', '28253', 'C', 'T', '5868'],\n",
       " ['NC_045512.2', '28387', 'A', 'C', '109'],\n",
       " ['NC_045512.2', '28461', 'A', 'G', '29706'],\n",
       " ['NC_045512.2', '28698', 'C', 'A', '7287'],\n",
       " ['NC_045512.2', '28836', 'C', 'T', '102'],\n",
       " ['NC_045512.2', '28851', 'G', 'T', '72'],\n",
       " ['NC_045512.2', '28853', 'T', 'A', '2280'],\n",
       " ['NC_045512.2', '28881', 'G', 'T', '9326'],\n",
       " ['NC_045512.2', '29402', 'G', 'T', '30263'],\n",
       " ['NC_045512.2', '29512', 'T', 'C', '44232'],\n",
       " ['NC_045512.2', '29581', 'T', 'C', '227'],\n",
       " ['NC_045512.2', '29742', 'G', 'T', '1184']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NC_045512.2\n",
       "1     NC_045512.2\n",
       "2     NC_045512.2\n",
       "3     NC_045512.2\n",
       "4     NC_045512.2\n",
       "         ...     \n",
       "68    NC_045512.2\n",
       "69    NC_045512.2\n",
       "70    NC_045512.2\n",
       "71    NC_045512.2\n",
       "72    NC_045512.2\n",
       "Name: Chromosome, Length: 73, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_df[\"Chromosome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       210\n",
       "1       241\n",
       "2       372\n",
       "3       441\n",
       "4      1055\n",
       "      ...  \n",
       "68    28881\n",
       "69    29402\n",
       "70    29512\n",
       "71    29581\n",
       "72    29742\n",
       "Name: Position, Length: 73, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_df[\"Position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Alternate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reference Alternate\n",
       "0          G         T\n",
       "1          C         T\n",
       "2          A         C\n",
       "3          G         A\n",
       "4          G         A\n",
       "..       ...       ...\n",
       "68         G         T\n",
       "69         G         T\n",
       "70         T         C\n",
       "71         T         C\n",
       "72         G         T\n",
       "\n",
       "[73 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_df[[\"Reference\", \"Alternate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Reference Alternate\n",
      "0         G         T\n",
      "1         C         T\n",
      "2         A         C\n",
      "3         G         A\n",
      "4         G         A\n"
     ]
    }
   ],
   "source": [
    "# Selecting only Reference and Alternate columns\n",
    "ref_alt_df = vcf_df[[\"Reference\", \"Alternate\"]]\n",
    "\n",
    "# Display the first few rows\n",
    "print(ref_alt_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Chromosome Position Reference Alternate Quality\n",
      "0   NC_045512.2      210         G         T   48519\n",
      "1   NC_045512.2      241         C         T   49314\n",
      "2   NC_045512.2      372         A         C     110\n",
      "3   NC_045512.2      441         G         A     105\n",
      "4   NC_045512.2     1055         G         A    1592\n",
      "..          ...      ...       ...       ...     ...\n",
      "68  NC_045512.2    28881         G         T    9326\n",
      "69  NC_045512.2    29402         G         T   30263\n",
      "70  NC_045512.2    29512         T         C   44232\n",
      "71  NC_045512.2    29581         T         C     227\n",
      "72  NC_045512.2    29742         G         T    1184\n",
      "\n",
      "[73 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# If you want to compare reference and alternated bases we can go ahead like this.\n",
    "\n",
    "mutations_df = vcf_df[vcf_df[\"Reference\"] != vcf_df[\"Alternate\"]]\n",
    "print(mutations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save it for future analysis use below!\n",
    "\n",
    "mutations_df.to_csv(\"filtered_mutations.csv\", index=False)\n",
    "print(\"Filtered mutations saved to 'filtered_mutations.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use try-except in File Handling?\n",
    "\n",
    "When working with VCF files or any large biological dataset, errors may occur due to:\n",
    "\n",
    "File not found → The file might not exist or be in the wrong directory.\n",
    "\n",
    "Corrupted data → The file may have missing or unexpected values.\n",
    "\n",
    "Incorrect data type → Parsing issues when converting strings to numbers.\n",
    "\n",
    "Using try-except, we can catch these errors and provide custom error messages or fallback solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"test.vcf\", \"r\") as file:\n",
    "        vcf_data = file.readlines()\n",
    "    print(\"File loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'test.vcf' was not found. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens here is our code is trying to open the file. If it is succesful, than printing the message. Otherwise (which is an exemption in this case), goes directly to the other part and giving the message back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Allele_Frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Allele_Frequency'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40571/2447789123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Apply safe conversion to the 'Allele_Frequency' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mvcf_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Allele_Frequency\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcf_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Allele_Frequency\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data processed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Allele_Frequency'"
     ]
    }
   ],
   "source": [
    "# Let's try something else...\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load extracted VCF data\n",
    "vcf_df = pd.read_csv(\"extracted_variants.csv\")\n",
    "\n",
    "# Handling missing values safely. Let's define a function\n",
    "\n",
    "def safe_convert(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None  # Return None if conversion fails\n",
    "\n",
    "# Apply safe conversion to the 'Allele_Frequency' column\n",
    "vcf_df[\"Allele_Frequency\"] = vcf_df[\"Allele_Frequency\"].apply(safe_convert)\n",
    "\n",
    "print(\"Data processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Extracting High-Quality Variants from a VCF File\n",
    "### Scenario\n",
    "You are analyzing a **Variant Call Format (VCF) file** containing genetic variants. Some variants have low **quality scores**, and you only want to keep those with **quality ≥ 1000**.\n",
    "\n",
    "### Task\n",
    "Write a Python program that:\n",
    "1. **Reads a VCF file** and extracts relevant variant data (Chromosome, Position, Reference, Alternate, Quality).\n",
    "2. **Filters variants** where `Quality ≥ 1000`.\n",
    "3. **Writes the filtered variants** to a new CSV file.\n",
    "\n",
    "\n",
    "# Your VCF file is in the data/ folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Problem 2: Handling Missing MIC Values in an AMR Dataset\n",
    "### Scenario\n",
    "You are working with an **Antimicrobial Resistance (AMR) dataset** containing **Minimum Inhibitory Concentration (MIC) values**. Some MIC values are **missing (NaN)**, and you need to handle them.\n",
    "\n",
    "### Task\n",
    "Write a Python program that:\n",
    "1. **Reads an AMR dataset (CSV file)**.\n",
    "2. **Finds missing MIC values** in the `MIC_µg/mL` column.\n",
    "3. **Fills missing values** with `\"Not Available\"` and saves the cleaned dataset.\n",
    "\n",
    "### Example Input (AMR Dataset Sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## **Solution for Problem 1: Extracting High-Quality Variants**\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the VCF file path\n",
    "vcf_file_path = \"data/test.vcf\"\n",
    "\n",
    "# Extract relevant data\n",
    "vcf_data = []\n",
    "\n",
    "# Open and read the VCF file\n",
    "with open(vcf_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\"#\"):  # Ignore metadata lines\n",
    "            columns = line.strip().split(\"\\t\")\n",
    "            chrom, pos, ref, alt, qual = columns[0], columns[1], columns[3], columns[4], columns[5]\n",
    "\n",
    "            # Store extracted data\n",
    "            vcf_data.append([chrom, pos, ref, alt, int(qual)])\n",
    "\n",
    "# Convert to DataFrame\n",
    "vcf_df = pd.DataFrame(vcf_data, columns=[\"Chromosome\", \"Position\", \"Reference\", \"Alternate\", \"Quality\"])\n",
    "\n",
    "# Filter variants with Quality >= 1000\n",
    "filtered_variants = vcf_df[vcf_df[\"Quality\"] >= 1000]\n",
    "\n",
    "# Save to CSV\n",
    "filtered_variants.to_csv(\"filtered_variants.csv\", index=False)\n",
    "\n",
    "print(\"Filtered variants saved to 'filtered_variants.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Solution for Problem 2:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the AMR dataset\n",
    "amr_df = pd.read_csv(\"data/amr_dataset.csv\")\n",
    "\n",
    "# Fill missing MIC values with \"Not Available\"\n",
    "amr_df[\"MIC_µg/mL\"].fillna(\"Not Available\", inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "amr_df.to_csv(\"cleaned_amr_data.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned AMR dataset saved to 'cleaned_amr_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Playground!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
